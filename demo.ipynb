{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CircRL Demo Notebook\n",
    "\n",
    "This notebook demonstrates how to use CircRL to run rollouts, cache\n",
    "activations, train linear probes on cached activations, and apply\n",
    "arbitrary hook functions during a rollout.\n",
    "\n",
    "Dependencies required for this demo can be installed with\n",
    "`pip install -r requirements_demo.txt`.\n",
    "\n",
    "Start with various required imports, and some boilerplate to download\n",
    "and open a pre-trained Pong-playing agent, and set up a Pong\n",
    "environment.\n",
    "\n",
    "(Note that this particular Pong environment has no stochasticity, so\n",
    "agents trained on it aren't very interesting to study in general -- but\n",
    "it perfectly fine for a demo of the tools.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A.L.E: Arcade Learning Environment (version 0.8.1+53f58b7)\n",
      "[Powered by Stella]\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch as t\n",
    "from einops import rearrange\n",
    "from IPython.display import display, Video, Image\n",
    "from moviepy.editor import VideoFileClip\n",
    "\n",
    "from huggingface_hub import hf_hub_download\n",
    "\n",
    "from stable_baselines3.common.env_util import make_atari_env\n",
    "from stable_baselines3.common.vec_env import VecFrameStack\n",
    "from stable_baselines3.common.policies import ActorCriticCnnPolicy\n",
    "from stable_baselines3 import PPO\n",
    "\n",
    "import plotly.express as px\n",
    "\n",
    "import circrl.hooks as chk\n",
    "import circrl.rollouts as cro\n",
    "import circrl.probing as cpr\n",
    "\n",
    "# Boilerplate to make sure we can reload modules\n",
    "try:\n",
    "    # pylint: disable=import-outside-toplevel\n",
    "    from IPython import get_ipython  # type: ignore\n",
    "\n",
    "    # pylint: enable=import-outside-toplevel\n",
    "\n",
    "    get_ipython().run_line_magic(\"reload_ext\", \"autoreload\")  # type: ignore\n",
    "    get_ipython().run_line_magic(\"autoreload\", \"2\")  # type: ignore\n",
    "except AttributeError:\n",
    "    pass\n",
    "\n",
    "# Suppress some necessary warnings for cleaner output\n",
    "# (E.g. messages about version differences with the saved policy used in\n",
    "# this demo)\n",
    "warnings.filterwarnings(\n",
    "    \"ignore\",\n",
    "    message=\".*You are probably loading a model saved with SB3.*\",\n",
    "    category=UserWarning,\n",
    ")\n",
    "warnings.filterwarnings(\n",
    "    \"ignore\",\n",
    "    message=\".*No render fps was declared in the environment.*\",\n",
    "    category=UserWarning,\n",
    ")\n",
    "warnings.filterwarnings(\n",
    "    \"ignore\",\n",
    "    message=\".*Precision and F-score are ill-defined.*\",\n",
    ")\n",
    "\n",
    "# Define an environment setup function\n",
    "def env_setup(seed):\n",
    "    env = make_atari_env(\n",
    "        \"PongNoFrameskip-v4\",\n",
    "        n_envs=1,\n",
    "        seed=seed,\n",
    "        # wrapper_kwargs={\"action_repeat_probability\": 0.25},\n",
    "    )\n",
    "    env = VecFrameStack(env, n_stack=4)\n",
    "    return env, {\"seed\": seed}\n",
    "\n",
    "\n",
    "# Download model, and load it for prediction\n",
    "model_path = hf_hub_download(\n",
    "    repo_id=\"sb3/ppo-PongNoFrameskip-v4\", filename=\"ppo-PongNoFrameskip-v4.zip\"\n",
    ")\n",
    "env = env_setup(0)[0]\n",
    "dummy_ppo = PPO(ActorCriticCnnPolicy, env, 0.0)\n",
    "# Custom object overrides are required for sb3 cross-version compatibility\n",
    "custom_objects = {\n",
    "    \"learning_rate\": 0.0,\n",
    "    \"lr_schedule\": lambda _: 0.0,\n",
    "    \"clip_range\": lambda _: 0.0,\n",
    "    \"observation_space\": dummy_ppo.observation_space,\n",
    "    \"action_space\": dummy_ppo.action_space,\n",
    "}\n",
    "model = PPO.load(model_path, custom_objects=custom_objects)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running rollouts\n",
    "\n",
    "Then we can use CircRL to run a bunch of rollouts and save the data to a new timestamped folder:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:18<00:00,  3.78s/it]\n"
     ]
    }
   ],
   "source": [
    "# Run many rollouts using CircRL\n",
    "cro.make_dataset(\n",
    "    model.predict,\n",
    "    \"Testing\",\n",
    "    \"datasets\",\n",
    "    5,\n",
    "    env_setup,\n",
    "    initial_seed=0,\n",
    "    run_rollout_kwargs=dict(show_pbar=False),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Caching activations\n",
    "\n",
    "We can also run a single rollout, and cache certain hidden-layer\n",
    "activations at each step during the rollout for use later.\n",
    "Specifically, in this case we cache the output of the first\n",
    "convolutional layer, and the action logits, which will use for a simple\n",
    "linear probing demo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1652it [00:03, 514.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1652, 32, 20, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Run a rollout while caching\n",
    "ACTIVS_LAYER = \"features_extractor.cnn.1\"\n",
    "LOGITS_LAYER = \"action_net\"\n",
    "activs_list = []\n",
    "logits_list = []\n",
    "\n",
    "\n",
    "def cache_predict(*args, **kwargs):\n",
    "    \"\"\"Custom predict func that caches activations from an intermediate\n",
    "    convolutional layer.\"\"\"\n",
    "    with chk.HookManager(\n",
    "        model.policy, cache=[ACTIVS_LAYER, LOGITS_LAYER]\n",
    "    ) as cache_result:\n",
    "        action = model.predict(*args, **kwargs)\n",
    "        activs_list.append(cache_result[ACTIVS_LAYER])\n",
    "        logits_list.append(cache_result[LOGITS_LAYER])\n",
    "    return action\n",
    "\n",
    "\n",
    "# Run a single episode using CircRL, using the custom predict function\n",
    "# that caches activations from an intermediate convolutional layer.\n",
    "# Create a new environment to ensure deterministic results\n",
    "env = env_setup(0)[0]\n",
    "seq, episode_return, step_cnt = cro.run_rollout(\n",
    "    cache_predict,\n",
    "    env,\n",
    "    max_episodes=1,\n",
    ")\n",
    "\n",
    "# Concatenate the cached activations so that batch dimension contains\n",
    "# all the chached timesteps\n",
    "activs = t.cat(activs_list, dim=0)\n",
    "logits = t.cat(logits_list, dim=0)\n",
    "print(activs.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training probes\n",
    "\n",
    "We can use these cached activations for a quick probing demo: \n",
    "1. We'll set up a boolearn probe target based on the action logits,\n",
    "   which will be True if the probability of the agent moving the paddle\n",
    "   up is very high (>90%), False otherwise.\n",
    "2. We'll train a sparse linear probe to predict this \"high probability\n",
    "   of paddle-up\" target using activations from the first convolutional\n",
    "   layer output -- in other words, try to find a linear combination of a\n",
    "   small number of activations that accurately predict the final action\n",
    "   probability.\n",
    "\n",
    "Spoiler alert: due to the simplicity and predictability of the default\n",
    "Pong environment, this sparse probe works surprisingly well even using\n",
    "only a very small fraction of activations.\n",
    "\n",
    "(Note that this isn't intended to represent a sensible mech interp\n",
    "research question -- just a simple and accessible example to demonstrate\n",
    "the probing functionality.  A more useful probe target might be \"pixel\n",
    "contains the ball\", or whatever.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg class=\"main-svg\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"700\" height=\"500\" style=\"\" viewBox=\"0 0 700 500\"><rect x=\"0\" y=\"0\" width=\"700\" height=\"500\" style=\"fill: rgb(255, 255, 255); fill-opacity: 1;\"/><defs id=\"defs-d8be3b\"><g class=\"clips\"><clipPath id=\"clipd8be3bxyplot\" class=\"plotclip\"><rect width=\"540\" height=\"320\"/></clipPath><clipPath class=\"axesclip\" id=\"clipd8be3bx\"><rect x=\"80\" y=\"0\" width=\"540\" height=\"500\"/></clipPath><clipPath class=\"axesclip\" id=\"clipd8be3by\"><rect x=\"0\" y=\"100\" width=\"700\" height=\"320\"/></clipPath><clipPath class=\"axesclip\" id=\"clipd8be3bxy\"><rect x=\"80\" y=\"100\" width=\"540\" height=\"320\"/></clipPath></g><g class=\"gradients\"/><g class=\"patterns\"/></defs><g class=\"bglayer\"><rect class=\"bg\" x=\"80\" y=\"100\" width=\"540\" height=\"320\" style=\"fill: rgb(229, 236, 246); fill-opacity: 1; stroke-width: 0;\"/></g><g class=\"layer-below\"><g class=\"imagelayer\"/><g class=\"shapelayer\"/></g><g class=\"cartesianlayer\"><g class=\"subplot xy\"><g class=\"layer-subplot\"><g class=\"shapelayer\"/><g class=\"imagelayer\"/></g><g class=\"minor-gridlayer\"><g class=\"x\"/><g class=\"y\"/></g><g class=\"gridlayer\"><g class=\"x\"><path class=\"xgrid crisp\" transform=\"translate(179.18,0)\" d=\"M0,100v320\" style=\"stroke: rgb(255, 255, 255); stroke-opacity: 1; stroke-width: 1px;\"/><path class=\"xgrid crisp\" transform=\"translate(289.39,0)\" d=\"M0,100v320\" style=\"stroke: rgb(255, 255, 255); stroke-opacity: 1; stroke-width: 1px;\"/><path class=\"xgrid crisp\" transform=\"translate(399.59,0)\" d=\"M0,100v320\" style=\"stroke: rgb(255, 255, 255); stroke-opacity: 1; stroke-width: 1px;\"/><path class=\"xgrid crisp\" transform=\"translate(509.8,0)\" d=\"M0,100v320\" style=\"stroke: rgb(255, 255, 255); stroke-opacity: 1; stroke-width: 1px;\"/></g><g class=\"y\"><path class=\"ygrid crisp\" transform=\"translate(0,390.72)\" d=\"M80,0h540\" style=\"stroke: rgb(255, 255, 255); stroke-opacity: 1; stroke-width: 1px;\"/><path class=\"ygrid crisp\" transform=\"translate(0,337.76)\" d=\"M80,0h540\" style=\"stroke: rgb(255, 255, 255); stroke-opacity: 1; stroke-width: 1px;\"/><path class=\"ygrid crisp\" transform=\"translate(0,284.8)\" d=\"M80,0h540\" style=\"stroke: rgb(255, 255, 255); stroke-opacity: 1; stroke-width: 1px;\"/><path class=\"ygrid crisp\" transform=\"translate(0,231.84)\" d=\"M80,0h540\" style=\"stroke: rgb(255, 255, 255); stroke-opacity: 1; stroke-width: 1px;\"/><path class=\"ygrid crisp\" transform=\"translate(0,178.88)\" d=\"M80,0h540\" style=\"stroke: rgb(255, 255, 255); stroke-opacity: 1; stroke-width: 1px;\"/><path class=\"ygrid crisp\" transform=\"translate(0,125.92)\" d=\"M80,0h540\" style=\"stroke: rgb(255, 255, 255); stroke-opacity: 1; stroke-width: 1px;\"/></g></g><g class=\"zerolinelayer\"/><path class=\"xlines-below\"/><path class=\"ylines-below\"/><g class=\"overlines-below\"/><g class=\"xaxislayer-below\"/><g class=\"yaxislayer-below\"/><g class=\"overaxes-below\"/><g class=\"plot\" transform=\"translate(80,100)\" clip-path=\"url(#clipd8be3bxyplot)\"><g class=\"scatterlayer mlayer\"><g class=\"trace scatter trace08ef4e\" style=\"stroke-miterlimit: 2; opacity: 1;\"><g class=\"fills\"/><g class=\"errorbars\"/><g class=\"lines\"><path class=\"js-line\" d=\"M0,304L44.08,112L99.18,48L209.39,16L540,16\" style=\"vector-effect: none; fill: none; stroke: rgb(99, 110, 250); stroke-opacity: 1; stroke-width: 2px; opacity: 1;\"/></g><g class=\"points\"/><g class=\"text\"/></g></g></g><g class=\"overplot\"/><path class=\"xlines-above crisp\" d=\"M0,0\" style=\"fill: none;\"/><path class=\"ylines-above crisp\" d=\"M0,0\" style=\"fill: none;\"/><g class=\"overlines-above\"/><g class=\"xaxislayer-above\"><g class=\"xtick\"><text text-anchor=\"middle\" x=\"0\" y=\"433\" transform=\"translate(179.18,0)\" style=\"font-family: 'Open Sans', verdana, arial, sans-serif; font-size: 12px; fill: rgb(42, 63, 95); fill-opacity: 1; white-space: pre; opacity: 1;\">10</text></g><g class=\"xtick\"><text text-anchor=\"middle\" x=\"0\" y=\"433\" style=\"font-family: 'Open Sans', verdana, arial, sans-serif; font-size: 12px; fill: rgb(42, 63, 95); fill-opacity: 1; white-space: pre; opacity: 1;\" transform=\"translate(289.39,0)\">20</text></g><g class=\"xtick\"><text text-anchor=\"middle\" x=\"0\" y=\"433\" style=\"font-family: 'Open Sans', verdana, arial, sans-serif; font-size: 12px; fill: rgb(42, 63, 95); fill-opacity: 1; white-space: pre; opacity: 1;\" transform=\"translate(399.59,0)\">30</text></g><g class=\"xtick\"><text text-anchor=\"middle\" x=\"0\" y=\"433\" style=\"font-family: 'Open Sans', verdana, arial, sans-serif; font-size: 12px; fill: rgb(42, 63, 95); fill-opacity: 1; white-space: pre; opacity: 1;\" transform=\"translate(509.8,0)\">40</text></g><g class=\"xtick\"><text text-anchor=\"middle\" x=\"0\" y=\"433\" style=\"font-family: 'Open Sans', verdana, arial, sans-serif; font-size: 12px; fill: rgb(42, 63, 95); fill-opacity: 1; white-space: pre; opacity: 1;\" transform=\"translate(620,0)\">50</text></g></g><g class=\"yaxislayer-above\"><g class=\"ytick\"><text text-anchor=\"end\" x=\"79\" y=\"4.199999999999999\" transform=\"translate(0,390.72)\" style=\"font-family: 'Open Sans', verdana, arial, sans-serif; font-size: 12px; fill: rgb(42, 63, 95); fill-opacity: 1; white-space: pre; opacity: 1;\">0.93</text></g><g class=\"ytick\"><text text-anchor=\"end\" x=\"79\" y=\"4.199999999999999\" style=\"font-family: 'Open Sans', verdana, arial, sans-serif; font-size: 12px; fill: rgb(42, 63, 95); fill-opacity: 1; white-space: pre; opacity: 1;\" transform=\"translate(0,337.76)\">0.94</text></g><g class=\"ytick\"><text text-anchor=\"end\" x=\"79\" y=\"4.199999999999999\" style=\"font-family: 'Open Sans', verdana, arial, sans-serif; font-size: 12px; fill: rgb(42, 63, 95); fill-opacity: 1; white-space: pre; opacity: 1;\" transform=\"translate(0,284.8)\">0.95</text></g><g class=\"ytick\"><text text-anchor=\"end\" x=\"79\" y=\"4.199999999999999\" style=\"font-family: 'Open Sans', verdana, arial, sans-serif; font-size: 12px; fill: rgb(42, 63, 95); fill-opacity: 1; white-space: pre; opacity: 1;\" transform=\"translate(0,231.84)\">0.96</text></g><g class=\"ytick\"><text text-anchor=\"end\" x=\"79\" y=\"4.199999999999999\" style=\"font-family: 'Open Sans', verdana, arial, sans-serif; font-size: 12px; fill: rgb(42, 63, 95); fill-opacity: 1; white-space: pre; opacity: 1;\" transform=\"translate(0,178.88)\">0.97</text></g><g class=\"ytick\"><text text-anchor=\"end\" x=\"79\" y=\"4.199999999999999\" style=\"font-family: 'Open Sans', verdana, arial, sans-serif; font-size: 12px; fill: rgb(42, 63, 95); fill-opacity: 1; white-space: pre; opacity: 1;\" transform=\"translate(0,125.92)\">0.98</text></g></g><g class=\"overaxes-above\"/></g></g><g class=\"polarlayer\"/><g class=\"smithlayer\"/><g class=\"ternarylayer\"/><g class=\"geolayer\"/><g class=\"funnelarealayer\"/><g class=\"pielayer\"/><g class=\"iciclelayer\"/><g class=\"treemaplayer\"/><g class=\"sunburstlayer\"/><g class=\"glimages\"/><defs id=\"topdefs-d8be3b\"><g class=\"clips\"/></defs><g class=\"layer-above\"><g class=\"imagelayer\"/><g class=\"shapelayer\"><g class=\"shape-group\" data-index=\"0\" clip-path=\"url(#clipd8be3by)\"><path data-index=\"0\" fill-rule=\"evenodd\" d=\"M80,353.4L620,353.4\" style=\"opacity: 1; stroke: rgb(0, 0, 0); stroke-opacity: 1; fill: rgb(0, 0, 0); fill-opacity: 0; stroke-dasharray: 9px, 9px; stroke-width: 2px;\"/></g></g></g><g class=\"infolayer\"><g class=\"g-gtitle\"><text class=\"gtitle\" x=\"35\" y=\"50\" text-anchor=\"start\" dy=\"0em\" style=\"font-family: 'Open Sans', verdana, arial, sans-serif; font-size: 17px; fill: rgb(42, 63, 95); opacity: 1; font-weight: normal; white-space: pre;\">Probe test accuracy vs number of pixels probed</text></g><g class=\"g-xtitle\"><text class=\"xtitle\" x=\"350\" y=\"460.3\" text-anchor=\"middle\" style=\"font-family: 'Open Sans', verdana, arial, sans-serif; font-size: 14px; fill: rgb(42, 63, 95); opacity: 1; font-weight: normal; white-space: pre;\">Number of pixels</text></g><g class=\"g-ytitle\"><text class=\"ytitle\" transform=\"rotate(-90,31.340625000000003,260)\" x=\"31.340625000000003\" y=\"260\" text-anchor=\"middle\" style=\"font-family: 'Open Sans', verdana, arial, sans-serif; font-size: 14px; fill: rgb(42, 63, 95); opacity: 1; font-weight: normal; white-space: pre;\">Test accuracy</text></g><g class=\"annotation\" data-index=\"0\" style=\"opacity: 1;\"><g class=\"annotation-text-g\" transform=\"rotate(0,595,344.4)\"><g class=\"cursor-pointer\" transform=\"translate(570,335)\"><rect class=\"bg\" x=\"0.5\" y=\"0.5\" width=\"49\" height=\"17\" style=\"stroke-width: 1px; stroke: rgb(0, 0, 0); stroke-opacity: 0; fill: rgb(0, 0, 0); fill-opacity: 0;\"/><text class=\"annotation-text\" text-anchor=\"middle\" x=\"25.015625\" y=\"13\" style=\"font-family: 'Open Sans', verdana, arial, sans-serif; font-size: 12px; fill: rgb(42, 63, 95); fill-opacity: 1; white-space: pre;\">Baseline</text></g></g></g></g></svg>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Demonstrate probing by finding conv pixels that seem to predict a high\n",
    "# probability of moving the paddle up\n",
    "\n",
    "# Get action meanings from the environment\n",
    "action_strs = env.envs[0].unwrapped.get_action_meanings()\n",
    "\n",
    "# Get the action indices that correspond to moving the paddle up, which\n",
    "# are RIGHT and RIGHTFIRE\n",
    "up_action_idxs = [action_strs.index(\"RIGHT\"), action_strs.index(\"RIGHTFIRE\")]\n",
    "\n",
    "# Convert the previously cached logits to probabilities\n",
    "probs = t.nn.functional.softmax(logits, dim=-1)\n",
    "\n",
    "# Calculate the sum of the probabilities of moving the paddle up\n",
    "up_probs = probs[:, up_action_idxs].sum(dim=-1)\n",
    "\n",
    "# Our probe objective variable is the a thresholded version\n",
    "is_strong_up = (up_probs > 0.9).cpu().numpy()\n",
    "\n",
    "# Now use CircRL to probe!\n",
    "# We use a sparse probe to see if we can find a small set of conv pixels\n",
    "# that predict strong paddle-up actions\n",
    "SPARSE_NUMS = [1, 5, 10, 20, 50]\n",
    "probe_results = []\n",
    "for sparse_num in SPARSE_NUMS:\n",
    "    result = cpr.linear_probe(\n",
    "        activs.cpu().numpy(),\n",
    "        is_strong_up,\n",
    "        sparse_method=\"f_test\",\n",
    "        sparse_num=sparse_num,\n",
    "        random_state=0,\n",
    "        C=1,\n",
    "    )\n",
    "    probe_results.append(\n",
    "        {\"sparse_num\": sparse_num, \"test_score\": result[\"test_score\"]}\n",
    "    )\n",
    "probe_results = pd.DataFrame(probe_results)\n",
    "\n",
    "baseline = is_strong_up.mean()\n",
    "baseline = max(baseline, 1 - baseline)\n",
    "\n",
    "fig = px.line(\n",
    "    probe_results,\n",
    "    x=\"sparse_num\",\n",
    "    y=\"test_score\",\n",
    "    title=\"Probe test accuracy vs number of pixels probed\",\n",
    "    labels={\"test_score\": \"Test accuracy\", \"sparse_num\": \"Number of pixels\"},\n",
    "    render_mode=\"svg\",\n",
    ")\n",
    "\n",
    "# Add a labelled horizontal line for the baseline accuracy\n",
    "fig.add_hline(\n",
    "    y=baseline,\n",
    "    line_dash=\"dash\",\n",
    "    line_color=\"black\",\n",
    "    annotation_text=\"Baseline\",\n",
    ")\n",
    "\n",
    "fig.show(\"svg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Patching and hooking\n",
    "\n",
    "Finally, we demonstrate the use of an arbitrary hook\n",
    "function to mean-ablate the 1% of activations in the same layer that are\n",
    "most predictive of the \"high probability of paddle-up\" target according\n",
    "to the f-test metric used in the sparse probing code by default.  We\n",
    "expect that this will cause the policy to miss important \"paddle-up\"\n",
    "actions and thus get worse performance (spoiler alert: it does, after\n",
    "this modification the agent only wins ~50% of points vs 100% for the\n",
    "unmodified model)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2685it [00:05, 507.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Building file demo1.gif with imageio.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                    \r"
     ]
    }
   ],
   "source": [
    "# Demonstrate custom hook functions mean-ablating the 1% of pixels that\n",
    "# are most predictive of moving the paddle up\n",
    "FRAC = 0.01\n",
    "\n",
    "activs_flat = rearrange(activs, \"b ... -> b (...)\")\n",
    "f_test, _ = cpr.f_classif_fixed(activs_flat.cpu().numpy(), is_strong_up)\n",
    "top_inds = t.tensor(\n",
    "    np.argsort(f_test)[::-1][: int(FRAC * f_test.shape[0])].copy()\n",
    ").to(activs.device)\n",
    "\n",
    "mean_activs_flat = activs_flat.mean(axis=0)\n",
    "\n",
    "\n",
    "def hook_func(input, output):\n",
    "    \"\"\"Custom hook function to mean-ablate certain pixels from a conv\n",
    "    layer.\"\"\"\n",
    "    # pylint: disable=unused-argument\n",
    "    # Flatten the output, patch the specific indices with the mean\n",
    "    # value, then return to the original shape\n",
    "    output_flat = rearrange(output, \"b c h w -> b (c h w)\")\n",
    "    output_flat[:, top_inds] = mean_activs_flat[top_inds]\n",
    "    output = rearrange(\n",
    "        output_flat,\n",
    "        \"b (c h w) -> b c h w\",\n",
    "        c=output.shape[1],\n",
    "        h=output.shape[2],\n",
    "    )\n",
    "    return output\n",
    "\n",
    "\n",
    "env = env_setup(0)[0]\n",
    "with chk.HookManager(model.policy, hook={ACTIVS_LAYER: hook_func}) as _:\n",
    "    # Run a single episode using CircRL\n",
    "    seq, episode_return, step_cnt = cro.run_rollout(\n",
    "        model.predict,\n",
    "        env,\n",
    "        max_episodes=1,\n",
    "    )\n",
    "\n",
    "# Make video\n",
    "vid_fn, fps = cro.make_video_from_renders(seq.renders, fps=30.0)\n",
    "\n",
    "# Display video (won't show in Github static view)\n",
    "# display(Video(vid_fn, embed=True, width=300))\n",
    "\n",
    "# Display GIF of first part of video\n",
    "clip = VideoFileClip(vid_fn).subclip(0, 10)\n",
    "clip.write_gif(\"demo1.gif\", fps=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![video gif](demo1.gif \"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "circrl-dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
